#+TITLE:     Presentation of Scientific Results
#+AUTHOR:    Arnaud Legrand
#+DATE: Performance Evaluation Lecture
#+STARTUP: beamer overview indent
#+TAGS: noexport(n)
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [11pt,xcolor=dvipsnames,presentation]
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+LATEX_HEADER: \input{org-babel-style-preembule.tex}

#+LaTeX: \input{org-babel-document-preembule.tex}


* List                                                             :noexport:
* Data Visualization
#+BEGIN_LaTeX
\def\info{
      \resizebox{\linewidth}{!}{
        \begin{minipage}{1.1\linewidth}
          \small
  $N = 11$ samples\\
  Mean of $X$ = 9.0\\
  Mean of $Y$ = 7.5\\%
  \uncover<2->{Intercept = 3\\
  Slope = 0.5\\
  Res. stdev = 1.237\\}%
  Correlation = 0.816
        \end{minipage}
      }
}
#+END_LaTeX

** Motivation
*** Why do we need to visualize ? The Anscombe's Quartet         :noexport:
#+begin_src R :results output :session :exports none
library(ggplot2)
library(plyr)
library(reshape)
anscombe$idx=1:length(anscombe$x1) 
a = melt(anscombe,id=c("idx"))
a$set=gsub("[^0-9]*","",as.character(a$variable))
a$variable=gsub("[0-9]*","",as.character(a$variable))
a = cast(a, idx+set~variable, mean) 
# library(ggplot2)
# library(dplyr)
# library(tidyr)
# anscombe$idx=1:length(anscombe$x1) 
# a = anscombe %>% gather(variable, value,-idx)
# a$set=gsub("[^0-9]*","",as.character(a$variable))
# a$variable=gsub("[0-9]*","",as.character(a$variable))
# a %>% spread(set,variable)
a = cast(a, idx+set~variable, mean) 
#+end_src

#+RESULTS:
: 
: Attachement du package : ‘reshape’
: 
: The following objects are masked from ‘package:plyr’:
: 
:     rename, round_any
: Erreur : Casting formula contains variables not found in molten data: variable

#+LaTeX: \begin{columns}\begin{column}{.4\linewidth}
#+begin_src R :results output :session :exports output
a1=a[a$set==1,c("x","y")]
a2=a[a$set==2,c("x","y")]
a1
#+end_src

#+RESULTS:
#+begin_example
    x     y
1  10  8.04
5   8  6.95
9  13  7.58
13  9  8.81
17 11  8.33
21 14  9.96
25  6  7.24
29  4  4.26
33 12 10.84
37  7  4.82
41  5  5.68
#+end_example

#+LaTeX: \end{column}\begin{column}{.6\linewidth}
#+begin_src R :results output :session :exports both
summary(a1)
summary(a2)
#+end_src

#+RESULTS:
#+begin_example
       x              y         
 Min.   : 4.0   Min.   : 4.260  
 1st Qu.: 6.5   1st Qu.: 6.315  
 Median : 9.0   Median : 7.580  
 Mean   : 9.0   Mean   : 7.501  
 3rd Qu.:11.5   3rd Qu.: 8.570  
 Max.   :14.0   Max.   :10.840
       x              y        
 Min.   : 4.0   Min.   :3.100  
 1st Qu.: 6.5   1st Qu.:6.695  
 Median : 9.0   Median :8.140  
 Mean   : 9.0   Mean   :7.501  
 3rd Qu.:11.5   3rd Qu.:8.950  
 Max.   :14.0   Max.   :9.260
#+end_example

#+LaTeX: \end{column}\end{columns}

*** Why do we need to visualize ? The Anscombe's Quartet
#+BEGIN_LaTeX
  \begin{columns}
    \begin{column}{.25\linewidth}
      $\small
      \begin{array}{|r|r|}\hline
        X^{(1)} & Y^{(1)} \n
        10.00 & 8.04  \n
        8.00  & 6.95  \n
        13.00 & 7.58  \n
        9.00  & 8.81  \n
        11.00 & 8.33  \n
        14.00 & 9.96  \n
        6.00  & 7.24  \n
        4.00  & 4.26  \n
        12.00 & 10.24 \n
        7.00  & 4.82  \n
        5.00  & 5.68  \n
      \end{array}
      $\medskip\\
      \info
    \end{column}
%
    \begin{column}{.25\linewidth}
      \only<4->{
      $\small
      \begin{array}{|r|r|}\hline
        X^{(2)} & Y^{(2)} \n
        10.00 & 9.14  \n
        8.00  & 8.14  \n
        13.00 & 8.74  \n
        9.00  & 8.77  \n
        11.00 & 9.26  \n
        14.00 & 8.10  \n
        6.00  & 6.13  \n
        4.00  & 3.10  \n
        12.00 & 9.13 \n
        7.00  & 7.26  \n
        5.00  & 4.74  \n
      \end{array}
      $\medskip\\
      \info
    }
    \end{column}
%
    \begin{column}{.25\linewidth}
      \only<4->{
      $\small
      \begin{array}{|r|r|}\hline
        X^{(3)} & Y^{(3)} \n
        10.00 & 7.46  \n
        8.00  & 6.77  \n
        13.00 & 12.74  \n
        9.00  & 7.11  \n
        11.00 & 7.81  \n
        14.00 & 8.84  \n
        6.00  & 6.08  \n
        4.00  & 5.39  \n
        12.00 & 8.15 \n
        7.00  & 6.42  \n
        5.00  & 5.73  \n
      \end{array}
      $\medskip\\
      \info
    }
    \end{column}
%
    \begin{column}{.25\linewidth}
      \only<4->{
      $\small
      \begin{array}{|r|r|}\hline
        X^{(4)} & Y^{(4)} \n
        8.00  & 6.58  \n
        8.00  & 5.76  \n
        8.00  & 7.71  \n
        8.00  & 8.84  \n
        8.00  & 8.47  \n
        8.00  & 7.04  \n
        8.00  & 5.25  \n
        19.00 &12.50  \n
        8.00  & 5.56 \n
        8.00  & 7.91  \n
        8.00  & 6.89  \n
      \end{array}
      $\medskip\\
      \info}
    \end{column}
  \end{columns}
  \begin{overlayarea}{1.1\linewidth}{0cm}
    \vspace{-8.2cm}\hspace{.15\linewidth}%
    \only<2-3,5-6>{%
      \begin{minipage}{.84\linewidth}
        \begin{alertblock}{}%
          \begin{columns}
          \null\hspace{-.6cm}%
            \begin{column}{.45\linewidth}
              \begin{block}{Scatter plot}
                \includegraphics<2-3>[width=\linewidth]{images/scat1.pdf}%
                \includegraphics<5-6>[width=\linewidth]{images/scat2.pdf}%
              \end{block}
            \end{column}\hspace{-.15\linewidth}
            \begin{column}{.5\linewidth}
              \small \only<3>{
                \begin{enumerate}
                \item The data set "behaves like" a linear curve with
                  some scatter;
                \item There is no justification for a more complicated
                  model (e.g., quadratic);
                \item There are no outliers;
                \item The vertical spread of the data appears to be of
                  equal height irrespective of the X-value; \\
                  this indicates that the data are equally-precise
                  throughout and so a "regular" (that is,
                  equi-weighted) fit is appropriate.
                \end{enumerate}}%
              \only<6>{
                \begin{enumerate}
                \item data set 1 is clearly linear with some scatter.
                \item data set 2 is clearly quadratic.
                \item data set 3 clearly has an outlier.
                \item data set 4 is obviously the victim of a poor
                  experimental design with a single point far removed
                  from the bulk of the data "wagging the dog".
                \end{enumerate}}
            \end{column}
%            \hspace{-2cm}
          \end{columns}
        \end{alertblock}
      \end{minipage}
    }
  \end{overlayarea}

#+END_LaTeX

*** Problem statement
- All *analysis* we perform rely on (sometimes implicit) *assumptions*. If
  these assumptions do not hold, the analysis will be a *complete
  non-sense*.
- Checking these assumptions is not always easy and sometimes, it may
  even be difficult to *list* all these assumptions and *formally state*
  them.
  #+BEGIN_CENTER
  \textbf{A visualization can help to check these assumptions.}
  #+END_CENTER
- Visual representation resort to our *cognitive faculties* to check
  properties.
  
  The visualization is meant to let us detect *expected and
  unexpected behavior* with respect to a given model.
*** Using the ``right'' representations
- The problem is to represent on a limited space, typically a screen
  with a fixed resolution, a meaningful information about the behavior
  of an application or system.
- $\leadsto$ need to aggregate data and be aware of what information
  loss this incurs.
- Every visualization *emphasizes* some characteristics and
  *hides* others. Being aware of the underlying models helps
  choosing the right representation.
*** Visualization and intuition
- Visualization can also be used to *guide your intuition*.

  Sometimes, you do not know exactly what you are looking for and
  looking at the data just helps.
- Some techniques (*Exploratory Data Analysis*) even build on
  this and propose to summarize main characteristics in
  easy-to-understand form, often with visual graphs, without using a
  statistical model or having formulated a hypothesis.
- \textbf{Use with care}, visualizations always have underlying
   models: when visualization is not adapted, what you may observe may
   be meaningless.

  Such approaches may *help formulating hypothesis* but these hypothesis
  have then to be tested upon new data-sets.  
*** A ``simple'' graphical check for investigating scalability
\small
Plotting $T_p$ versus $p$.
#+BEGIN_LaTeX
  \begin{center}
    \begin{overlayarea}{.6\linewidth}{4.4cm}
      \includegraphics<1-2>[width=\linewidth]{images/ipdps_plot_2.pdf}
      \includegraphics<3->[width=\linewidth]{images/ipdps_plot_1.pdf}
    \end{overlayarea}
  \end{center}
  \begin{overlayarea}{\linewidth}{2cm}
    \only<2>{
      \begin{itemize}
      \item y-axis does not start at 0, which makes speedup look more
        impressive\vspace{-.5em}
      \item x-axis is linear with an outlier.
      \end{itemize}
   }%
   \only<4>{
     \begin{itemize}
     \item y-axis uses log-scale\vspace{-.5em}
     \item x-axis is neither linear nor logarithmic so we cannot
       reason about the shape of the curve\vspace{-.5em}
     \end{itemize}
     Say, we want to test for Amhdal's law. Propose a better
     representation.}
  \end{overlayarea}
#+END_LaTeX
*** Graphically checking which alternative is better ?
\small 5 different alternatives (=FT-DWD_2=, =FT-DWD_5=, =FT-DWD_10=,
=RT-DWD=, =RT-BWD=), each tested 10 times.
#+BEGIN_CENTER
\begin{overlayarea}{.6\linewidth}{4cm}
\includegraphics[width=\linewidth]{images/ipdps_plot_3.pdf}
\end{overlayarea}
#+END_CENTER
\pause 
Outcomes have been sorted by increasing value for each alternative and
are then linked together
- The shape of the lines do not make any sense. The lines group
  related values\vspace{-.5em}
- Experiment order does not make any sense and makes it look like
  alternatives have been evaluated in 10 different settings (, which
  suggests the values can be compared with each others for each
  setting)\vspace{-.5em}
Propose a better representation
** Jain, Chapter 10
*** Read the basics
- For all such kind of ``general'' graphs where you summarize the
  results of several experiments, the very least you need to *read* is
  *Jain's book*: *The Art of Computer Systems Performance Analysis*. A new
  edition is expected in sept. 2015
- It has *check lists* for ``Good graphics'', which I made
  more or less available on the lecture's webpage
- It presents the most common pitfalls in data representation
- It will teach how to cheat with your figures\dots
- \dots and how to *detect cheaters*. ;)
*** Guidelines
1. Require minimum effort to the reader: get the message (legends,
   labels, trends, annotations, ...)
2. Maximize information (self-sufficient, clear labels, units, ...)
3. Minimize Ink (avoid cluttered information\dots)
4. Use commonly accepted practices (effect along the y-axis, scales)
5. Avoid Ambiguity (coordinates, scales, colors, only one variable, ...)
#+BEGIN_LaTeX
  \begin{center}
    \includegraphics<+>[height=4cm]{images/jain/10-02.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-03.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-04.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-05.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-06.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-07.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-08.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-13.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-09.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-10.jpg}
  \end{center}
#+END_LaTeX
*** What about these ones ?
#+BEGIN_CENTER
#+LaTeX: \includegraphics<+>[height=7cm]{images/jain/10-27.jpg}
#+END_CENTER
*** Use the right tools
- \textbf{R} :: is a system for statistical computation and graphics.
  - Avoid programming with R. Most things can be done with one liners.
  - Excellent graphic support with \textbf{ggplot2}.
  - =knitr= allows to mix R with LaTeX or Markdown. Literate
    programming to ease reproducible research.
- \textbf{Rstudio} :: is an IDE a system for statistical
  computation and graphics. It is easy to use and allows publishing
  on \textbf{rpubs}.
- \textbf{Org-mode} ::  Allows to mix sh, perl, R, \dots within plain text
     documents and export to LaTeX, HTML, ...  
* Needful R Packages by Hadley Wickam
** Plyr And Dplyr
*** plyr: the Split-Apply-Combine Strategy 
Have a look at http://plyr.had.co.nz/09-user/ for a more detailed
introduction. 
#+BEGIN_CENTER
 #+ATTR_LaTeX: :height 6cm
 [[./images/split-apply-combine.png]]
#+END_CENTER
*** plyr: Powerful One-liners
\small
#+BEGIN_SRC R :results output :exports both :session
library(plyr)
mtcars_summarized = ddply(mtcars,c("cyl","carb"), summarize, 
      num = length(wt), wt_mean = mean(wt), wt_sd = sd(wt),
      qsec_mean = mean(qsec), qsec_sd = sd(qsec));
mtcars_summarized
#+END_SRC

#+RESULTS:
#+begin_example
  cyl carb num  wt_mean     wt_sd qsec_mean   qsec_sd
1   4    1   5 2.151000 0.2627118  19.37800 0.6121029
2   4    2   6 2.398000 0.7485412  18.93667 2.2924368
3   6    1   2 3.337500 0.1732412  19.83000 0.5515433
4   6    4   4 3.093750 0.4131460  17.67000 1.1249296
5   6    6   1 2.770000        NA  15.50000        NA
6   8    2   4 3.560000 0.1939502  17.06000 0.1783255
7   8    3   3 3.860000 0.1835756  17.66667 0.3055050
8   8    4   6 4.433167 1.0171431  16.49500 1.4424112
9   8    8   1 3.570000        NA  14.60000        NA
#+end_example

*** dplyr
#+BEGIN_CENTER
  #+LaTeX: {\bf plyr next generation = dplyr}
#+END_CENTER

It's much much faster and more readable. The [[https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html][/tutorial/]] is great...

#+begin_src R :results output :session :exports both
library(dplyr)
mtcars %>% group_by(cyl,carb) %>%
           select(wt,qsec) %>%
           summarise(num = n(),
       wt_mean = mean(wt), wt_sd = sd(wt),
       qsec_mean = mean(qsec), qsec_sd = sd(qsec)) %>%
           filter(num>=1)   
#+end_src

#+RESULTS:
#+begin_example
 Source: local data frame [9 x 7]
Groups: cyl

  cyl carb num  wt_mean     wt_sd qsec_mean   qsec_sd
1   4    1   5 2.151000 0.2627118  19.37800 0.6121029
2   4    2   6 2.398000 0.7485412  18.93667 2.2924368
3   6    1   2 3.337500 0.1732412  19.83000 0.5515433
4   6    4   4 3.093750 0.4131460  17.67000 1.1249296
5   6    6   1 2.770000        NA  15.50000        NA
6   8    2   4 3.560000 0.1939502  17.06000 0.1783255
7   8    3   3 3.860000 0.1835756  17.66667 0.3055050
8   8    4   6 4.433167 1.0171431  16.49500 1.4424112
9   8    8   1 3.570000        NA  14.60000        NA
#+end_example

** Ggplot2
*** ggplot2: Modularity in Action
- =ggplot2= builds on plyr and on a modular *grammar of graphics*
- +obnoxious function with dozens of arguments+
- *combine* small functions using layers and transformations
- *aesthetic* mapping between *observation characteristics* (data frame column
  names) and *graphical* object *variables*
- an incredible *documentation*: http://docs.ggplot2.org/current/
  #+BEGIN_CENTER
  #+ATTR_LaTeX: :height 6cm
  [[./images/ggplot2_doc.png]]
  #+END_CENTER
*** ggplot2: Illustration (1)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot1.pdf :width 5.5 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=cyl)) +  
       geom_point();
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot1.pdf]]
#+END_CENTER
*** ggplot2: Illustration (2)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot2.pdf :width 5.5 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=factor(cyl))) +  
       geom_point();
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot2.pdf]]
#+END_CENTER
*** ggplot2: Illustration (3)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot3.pdf :width 5.5 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=factor(cyl),
       shape = factor(gear))) +  geom_point() + theme_bw() +
       geom_smooth(method="lm");
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot3.pdf]]
#+END_CENTER
*** ggplot2: Illustration (4)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot4.pdf :width 6 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=factor(cyl),
       shape = factor(gear))) + geom_point() + theme_bw() +
       geom_smooth(method="lm") + facet_wrap(~ cyl);
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot4.pdf]]
#+END_CENTER
*** ggplot2: Illustration (5)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot5.pdf :width 6 :height 4 :exports  both :session
ggplot(data = movies, aes(x=year,y=rating,group=factor(year))) + 
       geom_boxplot() + facet_wrap(~Romance)
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot5.pdf]]
#+END_CENTER
*** ggplot2: Illustration (6)
\small
# From [[http://www.cookbook-r.com/Graphs/Facets_(ggplot2)/#modifying-facet-label-text]]
#+begin_src R :results output :session :exports none
mf_labeller <- function(var, value){
    value <- as.character(value)
    if (var=="Action") { 
        value[value=="0"] <- "No action :("
        value[value=="1"]   <- "Action"
    }
    if (var=="Comedy") { 
        value[value=="0"] <- "Serious stuff!"
        value[value=="1"]   <- "Comedy :D"
    }
    return(value)
}
#+end_src

#+RESULTS:

#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot6.pdf :width 6 :height 4 :exports  both :session
ggplot(movies, aes(x = rating)) + geom_histogram(binwidth = 0.5)+
       facet_grid(Action ~ Comedy, labeller=mf_labeller) + theme_bw();
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot6.pdf]]
#+END_CENTER
** Reshape and tydiR
*** "Messy" data
When using ggplot or plyr, your data may not in the right shape, in
which case you should *give a try to reshape/melt*

#+begin_src R :results output :session :exports both

#+end_src

#+RESULTS:

#+begin_src R :results output :session :exports both
messy <- data.frame(
  name = c("Wilbur", "Petunia", "Gregory"),
  a = c(67, 80, 64),
  b = c(56, 90, 50)
)
messy
#+end_src

#+RESULTS:
:      name  a  b
: 1  Wilbur 67 56
: 2 Petunia 80 90
: 3 Gregory 64 50

- =a= and =b= are two different types of drugs and the values correspond to
  heart rate
- ggplot faceting or coloring based on the drug type is a pain
- we need a way to make "wide" data longer
*** Reshape
#+begin_src R :results output :session :exports both
library(reshape)
cleaner = melt(messy,c("name"))
names(cleaner)=c("name","drug","heartrate")
cleaner
#+end_src

#+RESULTS:
:      name drug heartrate
: 1  Wilbur    a        67
: 2 Petunia    a        80
: 3 Gregory    a        64
: 4  Wilbur    b        56
: 5 Petunia    b        90
: 6 Gregory    b        50

*** Tidyr
Just like plyr, reshape is a little magical. tidyr is the new
generation (faster, more coherent). Again, the [[http://blog.rstudio.org/2014/07/22/introducing-tidyr/][/tutorial/]] is
great.

#+begin_src R :results output :session :exports both
library(tidyr)
library(dplyr)
messy %>% gather(drug, heartrate, -name)
#+end_src

#+RESULTS:
:      name drug heartrate
: 1  Wilbur    a        67
: 2 Petunia    a        80
: 3 Gregory    a        64
: 4  Wilbur    b        56
: 5 Petunia    b        90
: 6 Gregory    b        50

*Hint:* Avoid mixing old-generation with new-generation as it overrides
some function names and leads to weird behaviors
** Now let's play!
*** Summarizing information
You may like these *cheat sheets*: 
#+BEGIN_CENTER
https://www.rstudio.com/resources/cheatsheets/
#+END_CENTER

#+begin_src R :results output :session :exports both
df = read.csv("data/set1.csv",header=T)
# Alternatively: read.csv("https://raw.githubusercontent.com/
#            alegrand/SMPE/master/lectures/data/set1.csv")
head(df,n=2)
#+end_src

#+RESULTS:
:          A        B
: 1 7.256717 8.261171
: 2 3.813100 4.335301

Get the following summary using =plyr/reshape= or =dplyr/tydir=:
#+begin_src R :results output :session :exports results
dfgg = df %>% gather(Alternative, Time) 
dfsum = dfgg %>% 
       group_by(Alternative) %>%
       summarise(num = n(),
                 mean = mean(Time),
                 sd = sd(Time),
		       min = min(Time),
		       max = max(Time))
dfsum
#+end_src

#+RESULTS:
: Source: local data frame [2 x 6]
: 
:   Alternative num     mean       sd      min       max
: 1           A  40 4.903817 1.544423 2.400016  9.172525
: 2           B  40 5.783643 1.542987 3.539874 10.027147
*** Plot the data
#+begin_src R :results output graphics :file pdf_babel/set1_1.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) +
    geom_point()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_1.pdf]]

*** Alleviate over-plotting
#+begin_src R :results output graphics :file pdf_babel/set1_2.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_point(alpha=.4) + theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_2.pdf]]
*** Avoid over-plotting
#+begin_src R :results output graphics :file pdf_babel/set1_3.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_3.pdf]]
*** Add summary information
#+begin_src R :results output graphics :file pdf_babel/set1_4.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
    geom_pointrange(data=dfsum,
                     aes(x=Alternative,y=mean,ymin=min,ymax=max)) +
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_4.pdf]]
*** Add more standard summaries
#+begin_src R :results output graphics :file pdf_babel/set1_5.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_boxplot(width=.4) +
    geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_5.pdf]]
*** Or use histograms...
#+begin_src R :results output graphics :file pdf_babel/set1_6.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Time,fill=Alternative)) + 
    geom_histogram() + facet_wrap(~Alternative,ncol=1) +
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_6.pdf]]
*** Be careful with fancy plots you do not fully understand!
#+begin_src R :results output graphics :file pdf_babel/set1_7.pdf :exports results :width 7 :height 4 :session
library(gridExtra)
p1 = ggplot(data=dfgg,aes(x=Time,fill=Alternative)) + 
     geom_histogram(aes(y = ..density..)) + 
     geom_density(alpha=.3) + facet_wrap(~Alternative,ncol=1) +
     theme_bw()
p2 = ggplot(data=dfgg,aes(x=Alternative,y=Time,fill=Alternative)) + 
     geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
     geom_dotplot(binaxis = "y", stackdir = "center") + 
     geom_violin(scale="area",trim=FALSE,alpha=.4) + theme_bw()
grid.arrange(p1,p2,nrow=1)
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_7.pdf]]
** Conclusion
*** Take away Message
- R, ggplot and other such tools are *incredibly powerful for
  presenting data*. They are much more high level than any other tools
  I have seen so far.
- Mastering it *will save you a lot of time* as it will allow to look at
  your data through *different angles* and thus *check many hypothesis*
  and *present* them *in the best possible way*
- Read at least Jain's book: *The Art of Computer Systems Performance
  Analysis*
- However, you may have started understanding that a visualization is
  meant to check or to illustrate one particular aspect and that this
  "aspect" relies on a *mathematical model*. I will thus explain you in
  the next lecture what this model is.

\textbf{To do for the Next Time}: Use what you just learned to improve
your data analysis, the article you're currently writing, ...\medskip


